{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import openpathsampling as paths\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openpathsampling.visualize as ops_vis\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the flexible path length simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file, and from the file pull our the engine (which tells us what the timestep was) and the move scheme (which gives us a starting point for much of the analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"tps_nc_files/alanine_dipeptide_tps.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flexible = paths.AnalysisStorage(filename)\n",
    "engine = flexible.engines[0]\n",
    "flex_scheme = flexible.schemes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"File size: {0} for {1} steps, {2} snapshots\".format(\n",
    "    flexible.file_size_str,\n",
    "    len(flexible.steps),\n",
    "    len(flexible.snapshots)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rough estimate of total time\n",
    "sum(step.change.details.timing for step in flexible.steps[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That tell us a little about the file we're dealing with. Now we'll start analyzing the contents of that file. We used a very simple move scheme (only shooting), so the main information that the `move_summary` gives us is the acceptance of the only kind of move in that scheme. See the MSTIS examples for more complicated move schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flex_scheme.move_summary(flexible.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replica history tree and decorrelated trajectories\n",
    "\n",
    "The `ReplicaHistoryTree` object gives us both the history tree (often called the \"move tree\") and the number of decorrelated trajectories.\n",
    "\n",
    "A `ReplicaHistoryTree` is made for a certain set of Monte Carlo steps. First, we make a tree of only the first 50 steps in order to visualize it. (All 10000 steps would be unwieldy.) \n",
    "\n",
    "After the visualization, we make a second `ReplicaHistoryTree` of all the steps, in order to count the number of decorrelated trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = ops_vis.PathTree(\n",
    "    flexible.steps[0:50],\n",
    "    ops_vis.ReplicaEvolution(\n",
    "        replica=0\n",
    "    )\n",
    ")\n",
    "\n",
    "SVG(tree.svg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Decorrelated trajectories:\", len(tree.generator.decorrelated_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path length distribution\n",
    "\n",
    "Flexible length TPS gives a distribution of path lengths. Here we calculate the length of every accepted trajectory, then histogram those lengths, and calculate the maximum and average path lengths.\n",
    "\n",
    "We also use `engine.snapshot_timestep` to convert the count of frames to time, including correct units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_lengths = [len(step.active[0].trajectory) for step in flexible.steps]\n",
    "plt.hist(path_lengths, bins=40, alpha=0.5);\n",
    "print \"Maximum:\", max(path_lengths), \"(\"+str(max(path_lengths)*engine.snapshot_timestep)+\")\"\n",
    "print \"Average:\", \"{0:.2f}\".format(np.mean(path_lengths)), \"(\"+(np.mean(path_lengths)*engine.snapshot_timestep).format(\"%.3f\")+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: path density plots (arbitrary dimension!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import nglview as nv\n",
    "#nv.show_mdtraj(traj.md())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the fixed path length simulation\n",
    "\n",
    "We start with the same sorts of analysis as we did in the flexible path length example: we get an overview of the file, then we look at the acceptance ratio, and then we look at the move history tree and the decorrelated trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed = paths.AnalysisStorage(\"tps_nc_files/alanine_dipeptide_fixed_tps.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = fixed.engines[0]\n",
    "fixed_scheme = fixed.schemes[0]\n",
    "\n",
    "print \"File size: {0} for {1} steps, {2} snapshots\".format(\n",
    "    fixed.file_size_str,\n",
    "    len(fixed.steps),\n",
    "    len(fixed.snapshots)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rough estimate of total time\n",
    "sum(step.change.details.timing for step in fixed.steps[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed_scheme.move_summary(fixed.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = ops_vis.PathTree(\n",
    "    fixed.steps[0:50],\n",
    "    ops_vis.ReplicaEvolution(\n",
    "        replica=0\n",
    "    )\n",
    ")\n",
    "print len(list(history.samples))\n",
    "\n",
    "SVG(history.svg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Decorrelated trajectories:\", len(history.generator.decorrelated_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of MC steps (and even more so, time steps) per decorrelated trajectory is much higher than in the case of flexible path length TPS. This is the heart of the argument that flexible path length approaches are more efficient than fixed path length approaches: with a fixed path length, it takes much more effort to get a decorrelated trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced analysis techniques\n",
    "\n",
    "Now we'll move on to a few more advanced analysis techniques. (These are discussed in Paper II.)\n",
    "\n",
    "With the fixed path length ensemble, we should check for recrossings. To do this, we create an ensemble which represents the recrossing paths: a frame in $\\beta$, possible frames in neither $\\alpha$ nor $\\beta$, and then a frame in $\\alpha$.\n",
    "\n",
    "Then we check whether any subtrajectory of a trial trajectory matches that ensemble, by using the `Ensemble.split()` function. We can then further refine to see which steps that included trials with recrossings were actually accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the ensemble that identifies recrossings\n",
    "alpha = fixed.volumes.find('alpha')\n",
    "beta = fixed.volumes.find('beta')\n",
    "recrossing_ensemble = paths.SequentialEnsemble([\n",
    "    paths.LengthEnsemble(1) & paths.AllInXEnsemble(beta),\n",
    "    paths.OptionalEnsemble(paths.AllOutXEnsemble(alpha | beta)),\n",
    "    paths.LengthEnsemble(1) & paths.AllInXEnsemble(alpha) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we check each step to see if its trial has a recrossing\n",
    "steps_with_recrossing = []\n",
    "for step in fixed.steps:\n",
    "    # trials is a list of samples: with shooting, only one in the list\n",
    "    recrossings = [] # default for initial empty move (no trials in step[0].change)\n",
    "    for trial in step.change.trials:\n",
    "        recrossings = recrossing_ensemble.split(trial.trajectory)\n",
    "        # recrossing contains a list with the recrossing trajectories\n",
    "        # (len(recrossing) == 0 if no recrossings)\n",
    "    if len(recrossings) > 0:\n",
    "        steps_with_recrossing += [step]  # save for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accepted_recrossings = [step for step in steps_with_recrossing if step.change.accepted is True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Trials with recrossings:\", len(steps_with_recrossing)\n",
    "print \"Accepted trials with recrossings:\", len(accepted_recrossings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the accepted trials with recrossing does not account for how long the trial remained active. It also doesn't tell us whether the trial represented a new recrossing event, or was correlated with the previous recrossing event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one of the accepted trajectories with a recrossing event. We'll plot the value of $\\psi$, since this is what distinguishes the two states. We'll also select the frames that are actually inside each state and color them (red for $\\alpha$, blue for $\\beta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psi = fixed.cvs.find('psi')\n",
    "trajectory = accepted_recrossings[0].active[0].trajectory\n",
    "in_alpha_indices = [trajectory.index(s) for s in trajectory if alpha(s)]\n",
    "in_alpha_psi = [psi(trajectory)[i] for i in in_alpha_indices]\n",
    "in_beta_indices = [trajectory.index(s) for s in trajectory if beta(s)]\n",
    "in_beta_psi = [psi(trajectory)[i] for i in in_beta_indices]\n",
    "\n",
    "plt.plot(psi(trajectory), 'k-')\n",
    "plt.plot(in_alpha_indices, in_alpha_psi, 'ro')  # alpha in red\n",
    "plt.plot(in_beta_indices, in_beta_psi, 'bo')  # beta in blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many recrossing events there are in each accepted trial. If there's one recrossing, then the trajectory much go $\\alpha\\to\\beta\\to\\alpha\\to\\beta$ to be accepted. Two recrossings would mean $\\alpha\\to\\beta\\to\\alpha\\to\\beta\\to\\alpha\\to\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recrossings_per = []\n",
    "for step in accepted_recrossings:\n",
    "    for test in step.change.trials:\n",
    "        recrossings_per.append(len(recrossing_ensemble.split(test.trajectory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print recrossings_per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the fixed and flexible simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transition path length distribution\n",
    "flex_ens = flex_scheme.network.sampling_ensembles[0]\n",
    "fixed_transition_segments = sum([flex_ens.split(step.active[0].trajectory) for step in fixed.steps],[])\n",
    "fixed_transition_length = [len(traj) for traj in fixed_transition_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(fixed_transition_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 400, 80);\n",
    "plt.hist(path_lengths, bins, alpha=0.5, normed=True, label=\"flexible\");\n",
    "plt.hist(fixed_transition_length, bins, alpha=0.5, normed=True, label=\"fixed\");\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying different mechanisms using custom ensembles\n",
    "\n",
    "We expected the plot above to be very similar for both cases. However, we know that the $\\alpha\\to\\beta$ transition in alanine dipeptide can occur via two mechanisms: since $\\psi$ is periodic, the transition can occur due to an overall increase in $\\psi$, or due to an overall decrease in $\\psi$. We also know that the alanine dipeptide transitions aren't actually all that rare, so they will occur spontaneously in long simulations.\n",
    "\n",
    "\n",
    "This section shows how to create custom ensembles to identify whether the transition occurred with an increasing $\\psi$ or a decreasing $\\psi$. We also need to account for (unlikely) edge cases where the path starts in one direction but completes the transition from the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll create a few more `Volume` objects. In this case, we will completely tile the Ramachandran space; while a complete tiling isn't necessary, it is often useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, we fully subdivide the Ramachandran space\n",
    "phi = fixed.cvs.find('phi')\n",
    "deg = 180.0/np.pi\n",
    "nml_plus = paths.CVRangeVolumePeriodic(psi, -160/deg, -100/deg, -np.pi, np.pi)\n",
    "nml_minus = paths.CVRangeVolumePeriodic(psi, 0/deg, 100/deg, -np.pi, np.pi)\n",
    "nml_alpha = (paths.CVRangeVolumePeriodic(phi, 0/deg, 180/deg, -np.pi, np.pi) &\n",
    "             paths.CVRangeVolumePeriodic(psi, 100/deg, 200/deg, -np.pi, np.pi))\n",
    "nml_beta = (paths.CVRangeVolumePeriodic(phi, 0/deg, 180/deg, -np.pi, np.pi) &\n",
    "            paths.CVRangeVolumePeriodic(psi, -100/deg, 0/deg, -np.pi, np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: plot to display where these volumes are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create ensembles for the \"increasing\" and \"decreasing\" transitions. These transitions mark a crossing of either the `nml_plus` or the `nml_minus`. These aren't necessarily $\\alpha\\to\\beta$ transitions. However, any $\\alpha\\to\\beta$ transition must contain at least one subtrajectory which satsifies one of these ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "increasing = paths.SequentialEnsemble([\n",
    "    paths.AllInXEnsemble(alpha | nml_alpha),\n",
    "    paths.AllInXEnsemble(nml_plus),\n",
    "    paths.AllInXEnsemble(beta | nml_beta)\n",
    "])\n",
    "decreasing = paths.SequentialEnsemble([\n",
    "    paths.AllInXEnsemble(alpha | nml_alpha),\n",
    "    paths.AllInXEnsemble(nml_minus),\n",
    "    paths.AllInXEnsemble(beta | nml_beta)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll write a little function that characterizes a set of trajectories according to these ensembles. It returns a dictionary mapping the ensemble (`increasing` or `decreasing`) to a list of trajectories that have a subtrajectory that satisfies it (at least one entry in `ensemble.split(trajectory)`). That dictionary also contains keys for `'multiple'` matched ensembles and `None` if no ensemble was matched. Trajectories for either of these keys would need to be investigated further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_transitions(ensembles, trajectories):\n",
    "    results = {ens : [] for ens in ensembles + ['multiple', None]}\n",
    "    for traj in trajectories:\n",
    "        matched_ens = None\n",
    "        for ens in ensembles:\n",
    "            if len(ens.split(traj)) > 0:\n",
    "                if matched_ens is not None:\n",
    "                    matched_ens = 'multiple'\n",
    "                else:\n",
    "                    matched_ens = ens\n",
    "        results[matched_ens].append(traj)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that function defined, let's use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorized = categorize_transitions(ensembles=[increasing, decreasing],\n",
    "                                     trajectories=fixed_transition_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"increasing:\", len(categorized[increasing])\n",
    "print \"decreasing:\", len(categorized[decreasing])\n",
    "print \"  multiple:\", len(categorized['multiple'])\n",
    "print \"      None:\", len(categorized[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the flexible length simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flex_trajs = [step.active[0].trajectory for step in flexible.steps]\n",
    "flex_categorized = categorize_transitions(ensembles=[increasing, decreasing],\n",
    "                                          trajectories=flex_trajs[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"increasing:\", len(flex_categorized[increasing])\n",
    "print \"decreasing:\", len(flex_categorized[decreasing])\n",
    "print \"  multiple:\", len(flex_categorized['multiple'])\n",
    "print \"      None:\", len(flex_categorized[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So the fixed length sampling is somehow capturing both kinds of transitions (probably because they are not really that rare). Let's see what the path length distribution from only the decreasing transitions looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist([len(traj) for traj in flex_categorized[decreasing]], bins, alpha=0.5, normed=True);\n",
    "plt.hist([len(traj) for traj in categorized[decreasing]], bins, alpha=0.5, normed=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a little off, although this might be due to bad sampling. Let's see how many of the decorrelated trajectories have this kind of transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start with the decorrelated tragectories\n",
    "fixed_decorrelated = full_history.decorrelated_trajectories\n",
    "# find the A->B transitions from the decorrelated trajectories\n",
    "decorrelated_transitions = sum([flex_ens.split(traj) for traj in fixed_decorrelated], [])\n",
    "# find the A->B transition from these which are decreasing\n",
    "decorrelated_decreasing = sum([decreasing.split(traj) for traj in decorrelated_transitions], [])\n",
    "print len(decorrelated_decreasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is based off of 11 decorrelated trajectory transitions. That's not a lot of statistics.\n",
    "\n",
    "However, we expect to see a *very* different distribution for the \"increasing\" paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist([len(traj) for traj in categorized[increasing]], bins, normed=True, alpha=0.5, color='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check whether we go back and forth between the increasing transition and the decreasing transition, or whether there's just a single change from one type to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_switches(ensembles, trajectories):\n",
    "    switches = []\n",
    "    last_category = None\n",
    "    traj_num = 0\n",
    "    for traj in trajectories:\n",
    "        category = None\n",
    "        for ens in ensembles:\n",
    "            if len(ens.split(traj)) > 0:\n",
    "                if category is not None:\n",
    "                    category = 'multiple'\n",
    "                else:\n",
    "                    category = ens\n",
    "        if last_category != category:\n",
    "            switches.append((category, traj_num))\n",
    "        traj_num += 1\n",
    "        last_category = category\n",
    "    return switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "switches = find_switches([increasing, decreasing], fixed_transition_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print [switch[1] for switch in switches], len(fixed_transition_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are a lot of switches early in the simulation, and then it gets stuck in one state for much longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we know the alanine dipeptide transitions are not particularly rare, this does give us reason to re-check the temperature. First we'll check what the intergrator says its temperature is, then we'll calculate the temperature based on the kinetic energy of every 50th trajectory.\n",
    "\n",
    "Note that the code below is specific to using the OpenMM engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print engine.integrator.getTemperature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "every_50th_trajectory = [step.active[0].trajectory for step in fixed.steps[::50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a set to remove duplicates, if trajs aren't decorrelated\n",
    "every_50th_traj_snapshots = list(set(sum(every_50th_trajectory, [])))\n",
    "# sadly, it looks like that trick with set doesn't do any good here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is ugly as sin: we need a better way of doing it (ideally as a snapshot feature)\n",
    "\n",
    "# dof calculation taken from OpenMM's StateDataReporter\n",
    "import simtk.openmm as mm\n",
    "import simtk.unit\n",
    "dof = 0\n",
    "system = engine.simulation.system\n",
    "dofs_from_particles = 0\n",
    "for i in range(system.getNumParticles()):\n",
    "    if system.getParticleMass(i) > 0*simtk.unit.dalton:\n",
    "        dofs_from_particles += 3\n",
    "dofs_from_constraints = system.getNumConstraints()\n",
    "dofs_from_motion_removers = 0\n",
    "if any(type(system.getForce(i)) == mm.CMMotionRemover for i in range(system.getNumForces())):\n",
    "    dofs_from_motion_removers += 3\n",
    "dof = dofs_from_particles - dofs_from_constraints - dofs_from_motion_removers\n",
    "#print dof, \"=\", dofs_from_particles, \"-\", dofs_from_constraints, \"-\", dofs_from_motion_removers\n",
    "\n",
    "kinetic_energies = []\n",
    "potential_energies = []\n",
    "temperatures = []\n",
    "R = simtk.unit.BOLTZMANN_CONSTANT_kB * simtk.unit.AVOGADRO_CONSTANT_NA\n",
    "for snap in every_50th_traj_snapshots:\n",
    "    engine.current_snapshot = snap\n",
    "    state = engine.simulation.context.getState(getEnergy=True)\n",
    "    ke = state.getKineticEnergy()\n",
    "    temperatures.append(2 * ke / dof / R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([T / T.unit for T in temperatures])\n",
    "mean_T = np.mean(temperatures)\n",
    "plt.plot([mean_T / mean_T.unit]*len(temperatures), 'r')\n",
    "print \"Mean temperature:\", np.mean(temperatures).format(\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is running a little hot, it is reasonable, and definitely not hot enough to blame for unexpected rare events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
